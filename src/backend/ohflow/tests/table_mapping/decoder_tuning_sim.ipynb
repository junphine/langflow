{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: 基于CPM-Bee进行解码层微调（decoder tuning）\n",
    "本教程基于情感分类数据集SST2对CPM-Bee进行解码层微调（decoder tuning）。解码层微调（decoder tuning）是在不训练模型的情况下，通过加入输出端的解码器网络，使用少样本训练解码器网络来提升模型的理解能力。我们将16 shot的微调结果与原始模型zero shot进行对比。\n",
    "\n",
    "This tutorial is based on the sentiment classification data set SST2 for CPM-Bee decoder tuning. decoder tuning is to improve the understanding ability of the model by joining the decoder network at the output end and training the decoder network with few samples without training the model. We compared the fine-tuning results of 16 shot to the original model zero shot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 数据格式处理 (Process dataset)\n",
    "训练之前，我们需要定义并处理我们的数据输入格式，我们构造一个数据集的处理类，将数据处理为特定格式。\n",
    "\n",
    "Before training, we need to define and process our data input format. We construct a processing class for the data set to process the data into a specific format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在本教程中，我们使用的情感分类的输入格式如下（也可以自行定义其他格式）：\n",
    "\n",
    "In this tutorial, we use the following input format for emotion classification (you can also define other formats) :\n",
    "```\n",
    "数据表1: table_name_cn,table_name_en,table description\n",
    "字段1: field_name_cn,field_name_en,field description\n",
    "数据表2: table2\n",
    "字段2: field2\n",
    "\"options\": {\n",
    "      \"<option_0>\": \"表不匹配, 字段不匹配\", \n",
    "      \"<option_1>\": \"表匹配，字段不匹配\",\n",
    "      \"<option_2>\": \"表匹配，字段匹配\",\n",
    "    }, \n",
    "question: \"输入的数据表1与数据表2是否匹配，并且字段1与字段2是否匹配?\"\n",
    "<ans>: <option_0>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "添加工作路径\n",
    "\n",
    "Add working path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "random.seed(123)\n",
    "sys.path.append(\"../../src\")\n",
    "sys.path.append(\"/data/nlp/llm/CPM/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SST2Processor():\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    dataset_project = {\"train\": \"train\",\n",
    "                        \"dev\": \"dev\",\n",
    "                        \"test\": \"test\"\n",
    "                        }\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.labels = ['0', '1']        \n",
    "        self.label_word = [\"不匹配\",\"表匹配，字段匹配\"]\n",
    "        self.verbalizer = {\"0\": \"不同\", \"1\": \"相同\"}\n",
    "    def get_examples(self, data_dir, split,shot =-1):\n",
    "        self.counts = {\"0\":0,\"1\":0,\"2\":0}\n",
    "        path = os.path.join(data_dir, f\"{self.dataset_project[split]}.jsonl\")\n",
    "        examples = []\n",
    "        with open(path, encoding='utf-8') as f:\n",
    "            lines = f.readlines()\n",
    "            for idx, line in enumerate(lines):\n",
    "                \n",
    "                example = json.loads(line)\n",
    "                guid = \"%s-%s\" % (split, idx)                \n",
    "                #print(line)\n",
    "                del example[\"options\"]\n",
    "                ans = example[\"<ans>\"]\n",
    "                #example[\"question\"] = \"What is the sentiment of this sentence?\"    \n",
    "                example['question'] = \"判断输入的表1+字段1与表2+字段2是否是同一个意思?\"\n",
    "                self.counts[ans]+=1\n",
    "                if ans=='2':\n",
    "                    example[\"<ans>\"]=  self.verbalizer['1']\n",
    "                else:\n",
    "                    example[\"<ans>\"]=  self.verbalizer['0']\n",
    "                if shot==-1:\n",
    "                    examples.append(example)\n",
    "                else:\n",
    "                    if self.counts[ans]>=shot:\n",
    "                        continue    \n",
    "                    else:\n",
    "                        examples.append(example)                        \n",
    "        return examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "添加不同的数据处理对象，以实现不同的数据格式。\n",
    "\n",
    "Add different data processing objects to implement different data formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROCESSORS = {\n",
    "    \"sim\": SST2Processor\n",
    "}\n",
    "dataset_name = \"sim\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/data/nlp/llm/CPM/CPM-Bee/tutorials/decoder_tuning\n"
     ]
    }
   ],
   "source": [
    "!pwd\n",
    "#!wget --content-disposition https://cloud.tsinghua.edu.cn/f/bccfdb243eca404f8bf3/?dl=1\n",
    "#!tar -zxvf SST-2.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "预处理数据格式，并且按照预处理格式将处理好的数据存储为二进制文件。训练集和验证集选取SST2数据集的train和dev文件中的数据并构造16 shot数据，测试集选取的为SST2数据集的test文件。文件路径在 ./decoder_tuning_data/raw_data/\n",
    "\n",
    "Preprocesse the data format, and the processed data is stored as binary files. The training set and verification set select the data in the train and dev files of the SST2 data set and construct 16 shot data, and the test set selects the test file of the SST2 data set. File path in ./decoder_tuning_data/raw_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Shuffle step 1/2: 100%|██████████| 12355/12355 [00:00<00:00, 180018.36it/s]\n",
      "Shuffle step 2/2: 100%|██████████| 1/1 [00:00<00:00, 28.52it/s]\n",
      "Shuffle step 1/2: 100%|██████████| 4941/4941 [00:00<00:00, 176419.99it/s]\n",
      "Shuffle step 2/2: 100%|██████████| 1/1 [00:00<00:00, 71.23it/s]\n",
      "Shuffle step 1/2: 100%|██████████| 4942/4942 [00:00<00:00, 174561.04it/s]\n",
      "Shuffle step 2/2: 100%|██████████| 1/1 [00:00<00:00, 69.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': 2426, '1': 44, '2': 2472}\n",
      "['不匹配', '表匹配，字段匹配']\n",
      "{'表1': '门(急)诊挂号表,registration_record', '字段1': '就诊机构代码,clinic_organ_code,医疗机构在国家直报系统中的12位编码（?如：520000000001）', '表2': '卫生事件入口活动信息,hevent_entrance', '字段2': '医疗机构原始编号,org_id,医疗机构按照原始编码体系填写的唯一标识', 'question': '判断输入的表1+字段1与表2+字段2是否是同一个意思?', '<ans>': '相同'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from cpm_live.dataset import build_dataset, shuffle_dataset\n",
    "\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "def build_bin_data(data,output_dir, dataset_path,dataset_name):\n",
    "    output_path = \"./decoder_tuning_data/bin_data/\"  +output_dir\n",
    "\n",
    "    with build_dataset(\"tmp\", \"data\") as dataset:\n",
    "        for item in data:\n",
    "            dataset.write(item) # reformat_data(item)\n",
    "    shuffle_dataset(\n",
    "        \"tmp\",\n",
    "        os.path.join(output_path, dataset_path),\n",
    "        progress_bar=True,\n",
    "        output_name=dataset_name\n",
    "    )\n",
    "    shutil.rmtree(\"tmp\")\n",
    "\n",
    "processor = PROCESSORS[dataset_name]()\n",
    "path = 'decoder_tuning_data/raw_data/' + dataset_name\n",
    "train_dataset = processor.get_examples(path,\"train\",shot=-1)\n",
    "\n",
    "valid_dataset = processor.get_examples(path,\"dev\",shot=-1)\n",
    "\n",
    "test_dataset = processor.get_examples(path,\"test\")\n",
    "if os.path.exists(\"./decoder_tuning_data/bin_data\"):\n",
    "    os.system(\"rm -rf ./decoder_tuning_data/bin_data/{}\".format(dataset_name))\n",
    "if os.path.exists(\"./tmp\"): \n",
    "    os.system(\"rm -rf ./tmp\")\n",
    "output_dir = dataset_name\n",
    "build_bin_data(train_dataset,output_dir, \"train_data\", \"example-data\")\n",
    "build_bin_data(valid_dataset,output_dir, \"valid_data\", \"example-data\")\n",
    "build_bin_data(test_dataset,output_dir, \"test_data\", \"example-data\")\n",
    "counts = processor.counts\n",
    "label_word = processor.label_word\n",
    "verbalizer = processor.verbalizer\n",
    "\n",
    "print(counts)\n",
    "print(label_word)\n",
    "print(train_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 训练（Training）\n",
    "我们自定义一个DecT_CPM类，方便实现在CPMBee上的decoder tuning，通过DecT_CPM中的run，run_zs函数分别实现16-shot下的decoder tuning和0-shot下的原本模型能力的测试。需要将预训练好的模型存储在`./ckpt/`文件夹下。具体而言，`./ckpt/`文件夹需要预先保存`./ckpt/config.json`、`./ckpt/pytorch_model.bin`和`./ckpt/vocab.txt`。\n",
    "\n",
    "We customize a DecT_CPM class to facilitate the realization of decoder tuning on CPMBee. Through the run and run_zs functions in DecT_CPM, decoder tuning under 4-shot and the original model ability test under 0-shot can be realized respectively. The pre-trained model needs to be stored in the './ckpt/ 'folder. Specifically, the './ckpt/ 'folder needs to be pre-stored'./ckpt/config.json ', './ckpt/pytorch_model.bin 'and'./ckpt/vocab.txt '."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "初始化一些超参数\n",
    "\n",
    "Initialize some hyperparameters and verbalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化一些超参数以及verbalizer\n",
    "lr = 4e-3\n",
    "proto_dim = 128\n",
    "model_logits_weight = 1\n",
    "max_epochs = 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "构造decoder_tuning的trainer，decoder tuning的主体模型是一个线性层，当数据量较大时，可以增加层数，以提升模型的学习能力。\n",
    "\n",
    "Construct the trainer of decoder_tuning. The main model of decoder tuning is a linear layer. When the amount of data is large, the number of layers can be increased to improve the learning ability of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "import sys\n",
    "sys.path.append(\".\")\n",
    "import time\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import dill\n",
    "import warnings\n",
    "from typing import Optional\n",
    "from typing import Callable, Union, Dict, List\n",
    "try:\n",
    "    from typing import OrderedDict\n",
    "except ImportError:\n",
    "    from collections import OrderedDict\n",
    "from sklearn.metrics import accuracy_score\n",
    "from copy import deepcopy\n",
    "\n",
    "class DecTCPM(object):\n",
    "    r\"\"\"A runner for DecT\n",
    "    This class is specially implemented for classification.\n",
    "    Decoder Tuning: Efficient Language Understanding as Decoding : https://arxiv.org/pdf/2212.08408.pdf\n",
    "\n",
    "    Args:\n",
    "        model (:obj:`CPMBeeTorch`): One ``CPMBeeTorch`` object.\n",
    "        test_dataloader (:obj:`FinetuneDataset`): The dataloader to bachify and process the test data.\n",
    "        tokenizer (:obj:`CPMBeeTokenizer`): The tokenizer to process the word.\n",
    "        verbalizer (:obj:`Verbalizer`): The verbalizer to map the label to the word.\n",
    "        device (:obj:`torch.device`): The device to run the model.\n",
    "        calibrate_dataloader (:obj:`FinetuneDataset`, optional): The dataloader that has empty input, to modify the output logits. Defaults to None.\n",
    "        lr (:obj:`float`, optional): The learning rate. Defaults to 5e-3.\n",
    "        hidden_size (:obj:`int`, optional): The hidden size of the model. Defaults to 4096.\n",
    "        mid_dim (:obj:`int`, optional): The dimension of the proto vector. Defaults to 128.\n",
    "        epochs (:obj:`int`, optional): The number of epochs to train. Defaults to 5.\n",
    "        model_logits_weight (:obj:`float`, optional): The weight of the model logits. Defaults to 1.\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 model,\n",
    "                 test_dataloader,\n",
    "                 val_dataloader,\n",
    "                 tokenizer,\n",
    "                 verbalizer,\n",
    "                 device: Optional[Union[str, torch.device]] = \"cuda:0\",\n",
    "                 calibrate_dataloader: Optional[List] = None,\n",
    "                 lr: Optional[float] = 5e-3,\n",
    "                 hidden_size: Optional[int] = 4096,\n",
    "                 mid_dim: Optional[int] = 128,\n",
    "                 epochs: Optional[int] = 5,\n",
    "                 model_logits_weight: Optional[float] = 1,\n",
    "                 ):\n",
    "        self.model = model\n",
    "        self.val_dataloader = val_dataloader\n",
    "        self.test_dataloader = test_dataloader\n",
    "        self.calibrate_dataloader = calibrate_dataloader\n",
    "        self.loss_function = torch.nn.CrossEntropyLoss()\n",
    "        self.device = device\n",
    "        ids = []\n",
    "        for idx in range(len(verbalizer.items())):\n",
    "            ids.append(tokenizer.encode(verbalizer[str(idx)])[0][0])\n",
    "        self.label_list = list(verbalizer.values())\n",
    "        self.label_word_token_ids = []\n",
    "        for label_word in self.label_list:\n",
    "            self.label_word_token_ids.append(tokenizer.encode(label_word)[0][0])\n",
    "        self.ids = ids #nn.Parameter(torch.tensor(ids), requires_grad=False)\n",
    "        self.num_classes = len(self.ids)\n",
    "        self.lr = lr\n",
    "        self.mid_dim = mid_dim\n",
    "        self.epochs = epochs\n",
    "        self.model_logits_weight = model_logits_weight\n",
    "        self.hidden_dims = hidden_size\n",
    "        self.reset_parameter()\n",
    "    \n",
    "    # reset the parameters, useful when you want to test different random seeds\n",
    "    # self.head is a linear layer, if you want to use other models, you can modify it (useful when there are more data)\n",
    "    def reset_parameter(self):\n",
    "        self.head = nn.Linear(self.hidden_dims, self.mid_dim, bias=False)\n",
    "        w = torch.empty((self.num_classes, self.mid_dim)).to(self.device)\n",
    "        nn.init.xavier_uniform_(w)\n",
    "        self.proto = nn.Parameter(w, requires_grad=False)\n",
    "        r = torch.ones(self.num_classes)\n",
    "        self.proto_r = nn.Parameter(r, requires_grad=True)\n",
    "        self.optimizer = torch.optim.Adam([p for n, p in self.head.named_parameters()] + [self.proto_r], lr=self.lr)\n",
    "\n",
    "\n",
    "    # get the logits and hidden states of the model, specifically for cpmbee model, you can modify it for other models\n",
    "    def get_logits_and_hidden(self,data):\n",
    "        input_ids = torch.from_numpy(data[\"inputs\"]).cuda().to(torch.int32)\n",
    "        input_ids_sub = torch.from_numpy(data[\"inputs_sub\"]).cuda().to(torch.int32)\n",
    "        input_length = torch.from_numpy(data[\"length\"]).cuda().to(torch.int32)\n",
    "        input_context = torch.from_numpy(data[\"context\"]).cuda().bool()\n",
    "        input_sample_ids = torch.from_numpy(data[\"sample_ids\"]).cuda().to(torch.int32)\n",
    "        input_num_segments = torch.from_numpy(data[\"num_segments\"]).cuda().to(torch.int32)\n",
    "        input_segment_ids = torch.from_numpy(data[\"segment_ids\"]).cuda().to(torch.int32)\n",
    "        input_segment_rel_offset = (\n",
    "            torch.from_numpy(data[\"segment_rel_offset\"]).cuda().to(torch.int32)\n",
    "        )\n",
    "        input_segment_rel = torch.from_numpy(data[\"segment_rel\"]).cuda().to(torch.int32)\n",
    "        input_span = torch.from_numpy(data[\"spans\"]).cuda().to(torch.int32)\n",
    "        targets = torch.from_numpy(data[\"target\"]).cuda().to(torch.int32)\n",
    "        ext_table_ids = torch.from_numpy(data[\"ext_ids\"]).cuda().to(torch.int32)\n",
    "        ext_table_sub = torch.from_numpy(data[\"ext_sub\"]).cuda().to(torch.int32)\n",
    "        task_ids = torch.from_numpy(data[\"task_ids\"]).cuda().to(torch.int32)\n",
    "        task_names = data[\"task_names\"]\n",
    "        # to get the label from the targets\n",
    "        mask = torch.logical_or(targets ==self.ids[0], targets==self.ids[1])\n",
    "        labels = targets[mask]\n",
    "        final_label = []\n",
    "        for i in range(len(labels)):\n",
    "            final_label.append(self.ids.index(labels[i]))\n",
    "        with torch.no_grad():\n",
    "            logits, hidden_states = self.model(\n",
    "                    input_ids,\n",
    "                    input_ids_sub,\n",
    "                    input_length,\n",
    "                    input_context,\n",
    "                    input_sample_ids,\n",
    "                    input_num_segments,\n",
    "                    input_segment_ids,\n",
    "                    input_segment_rel_offset,\n",
    "                    input_segment_rel,\n",
    "                    input_span,\n",
    "                    ext_table_ids,\n",
    "                    ext_table_sub,\n",
    "                )\n",
    "        # mask the targets where value is -100 or 7, to get the index of the valid position\n",
    "        mask_matrix = deepcopy(targets)\n",
    "        mask_matrix[targets == -100] = 0\n",
    "        mask_matrix[targets == 7] = 0\n",
    "        index_mask = mask_matrix.nonzero(as_tuple=False)\n",
    "        # finally we get the logits and hidden states of the <ans> word position\n",
    "        filtered_logits = logits[index_mask[:, 0], index_mask[:, 1], :]\n",
    "        filtered_hiddens = hidden_states[index_mask[:, 0], index_mask[:, 1], :]\n",
    "        label_logits = filtered_logits[:,self.label_word_token_ids] # F.softmax(filtered_logits)[:,self.label_word_token_ids]\n",
    "        return label_logits, filtered_hiddens,final_label\n",
    "    \n",
    "    # test the model on the dev set, if zs is true, then test on the zero-shot setting, otherwise test on the decoder tuning setting\n",
    "    def test(self, dataloader,zs):\n",
    "        if zs:\n",
    "            preds = []\n",
    "            labels = []\n",
    "            for iteration, data in enumerate(dataloader):\n",
    "                if data is None:\n",
    "                    if last_data is None:\n",
    "                        raise RuntimeError(\n",
    "                            \"Dataset is too small, please use a smaller batch size or sequence length!\"\n",
    "                        )\n",
    "                    data = last_data  # use last data\n",
    "                    skip_this_batch = True\n",
    "                else:\n",
    "                    last_data = data\n",
    "                logits,_,label = self.get_logits_and_hidden(data)\n",
    "                preds.extend(torch.argmax(logits, dim=-1).cpu().tolist())\n",
    "                labels.extend(label)\n",
    "            res = sum([int(i==j) for i,j in zip(preds, labels)])/len(preds)\n",
    "            return res\n",
    "        else:\n",
    "            preds = []\n",
    "            labels = []\n",
    "            for iteration, data in enumerate(dataloader):\n",
    "                if data is None:\n",
    "                    if last_data is None:\n",
    "                        raise RuntimeError(\n",
    "                            \"Dataset is too small, please use a smaller batch size or sequence length!\"\n",
    "                        )\n",
    "                    data = last_data  # use last data\n",
    "                    skip_this_batch = True\n",
    "                else:\n",
    "                    last_data = data\n",
    "                logits,hidden_states,label = self.get_logits_and_hidden(data)\n",
    "                proto_logits = self.sim(self.head(hidden_states.float()), self.proto, self.proto_r, logits.float(), self.model_logits_weight).cpu()\n",
    "                preds.extend(torch.argmax(proto_logits, dim=-1).cpu().tolist())\n",
    "                labels.extend(label)\n",
    "            res = sum([int(i==j) for i,j in zip(preds, labels)])/len(preds)\n",
    "            return res\n",
    "\n",
    "    @staticmethod\n",
    "    def sim(x, y, r=0, model_logits=0, model_logits_weight=1):\n",
    "        x = torch.unsqueeze(x, -2)\n",
    "        x = F.normalize(x, dim=-1)\n",
    "        d = torch.norm((x - y), dim=-1)\n",
    "        dist = d - model_logits * model_logits_weight - r\n",
    "        return -dist\n",
    "    \n",
    "    # conduct the loss function in the decoder tuning\n",
    "    def loss_func(self, x, model_logits, labels):\n",
    "        sim_mat = torch.exp(self.sim(x, self.proto, self.proto_r, model_logits, self.model_logits_weight))\n",
    "        pos_score = torch.sum(sim_mat * F.one_hot(labels), -1)\n",
    "        loss = -torch.mean(torch.log(pos_score / sim_mat.sum(-1)))\n",
    "        return loss\n",
    "    \n",
    "    # run zero shot setting\n",
    "    def run_zs(self):\n",
    "        res = self.test(self.test_dataloader, zs = True)\n",
    "        print(\"zero shot acc:\",res)\n",
    "\n",
    "    # train the model with decoder tuning, you need to provide the training dataloader (type:FinetuneDataset)\n",
    "    def run(self, train_dataloader):\n",
    "        logits_list = []\n",
    "        hidden_states_list = []\n",
    "        labels = []\n",
    "        with torch.no_grad():\n",
    "            for iteration, data in enumerate(train_dataloader):\n",
    "                if data is None:\n",
    "                    if last_data is None:\n",
    "                        raise RuntimeError(\n",
    "                            \"Dataset is too small, please use a smaller batch size or sequence length!\"\n",
    "                        )\n",
    "                    data = last_data  # use last data\n",
    "                    skip_this_batch = True\n",
    "                else:\n",
    "                    last_data = data\n",
    "                train_logits, train_embeds,label = self.get_logits_and_hidden(data)\n",
    "                logits_list.append(train_logits)\n",
    "                hidden_states_list.append(train_embeds)\n",
    "                labels.extend(label)\n",
    "        train_logits = torch.cat(logits_list,dim=0)\n",
    "        train_embeds = torch.cat(hidden_states_list,dim=0)\n",
    "        embeds = [[] for _ in range(self.num_classes)]\n",
    "        train_labels = [[] for _ in range(self.num_classes)]\n",
    "        model_logits = [[] for _ in range(self.num_classes)]\n",
    "        total_num = 0\n",
    "        start_time = time.time()\n",
    "        print(labels)\n",
    "        for idx, label in enumerate(labels):\n",
    "            label = torch.tensor(label)\n",
    "            train_labels[label].append(label)\n",
    "            embeds[label].append(torch.tensor(train_embeds[idx]))\n",
    "            model_logits[label].append(torch.tensor(train_logits[idx]))\n",
    "        embeds = list(map(torch.stack, embeds))\n",
    "        labels = torch.cat(list(map(torch.stack, train_labels))).to(self.device)\n",
    "        model_logits = torch.cat(list(map(torch.stack, model_logits))).float()\n",
    "\n",
    "        self.head.to(self.device)\n",
    "        self.proto.to(self.device)\n",
    "        self.proto_r.to(self.device)\n",
    "        dist = list(map(lambda x: torch.norm(self.head(x.float()) - self.head(x.float().mean(0)), dim=-1).mean(), embeds))\n",
    "        self.proto_r.data = torch.stack(dist)\n",
    "        \n",
    "        loss = 0.\n",
    "        best_eval_res = 0.\n",
    "        \n",
    "        for epoch in range(self.epochs):\n",
    "            x = self.head(torch.cat(embeds).float())\n",
    "            self.optimizer.zero_grad()\n",
    "            loss = self.loss_func(x, model_logits, labels)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            # use vaild dataset to evaluate the model, and test on best_eval_res\n",
    "            if epoch % 20 == 0 and epoch > 0 :\n",
    "                print(\"Total epoch: {}. DecT loss: {}\".format(epoch, loss))\n",
    "                eval_res = self.test(self.val_dataloader, zs = False)\n",
    "                print(\"val acc:\", eval_res)\n",
    "                if eval_res > best_eval_res:\n",
    "                    best_eval_res = eval_res\n",
    "                    test_res = self.test(self.test_dataloader, zs = False)\n",
    "                    print(\"test acc at best val:\",test_res)\n",
    "\n",
    "\n",
    "        end_time = time.time()\n",
    "        print(\"Total time: {}\".format(end_time - start_time))\n",
    "        res= self.test(self.test_dataloader, zs = False)\n",
    "        print(\"Final acc:\",res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加载模型的权重并部署\n",
    "\n",
    "Load the model's weights and deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cpm_live.tokenizers import CPMBeeTokenizer\n",
    "from cpm_live.training_tasks.bee import FinetuneDataset\n",
    "from cpm_live.models import CPMBeeConfig, CPMBeeTorch\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import bmtrain as bmt\n",
    "from copy import deepcopy\n",
    "model_path = '/data/nlp/models/OpenBMB/cpm-bee-10b/'\n",
    "config = CPMBeeConfig.from_json_file(model_path+\"config.json\")\n",
    "ckpt_path = model_path+\"/pytorch_model.bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = CPMBeeTokenizer()\n",
    "model = CPMBeeTorch(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CPMBeeTorch(\n",
       "  (encoder): Encoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-47): 48 x TransformerBlock(\n",
       "        (self_att): SelfAttentionBlock(\n",
       "          (layernorm_before_attention): LayerNorm()\n",
       "          (self_attention): Attention(\n",
       "            (project_q): Linear()\n",
       "            (project_k): Linear()\n",
       "            (project_v): Linear()\n",
       "            (attention_out): Linear()\n",
       "            (softmax): Softmax(dim=-1)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (ffn): FFNBlock(\n",
       "          (layernorm_before_ffn): LayerNorm()\n",
       "          (ffn): FeedForward(\n",
       "            (w_in): DenseGatedACT(\n",
       "              (w_0): Linear()\n",
       "              (w_1): Linear()\n",
       "              (act): GELU(approximate='none')\n",
       "            )\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (w_out): Linear()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (output_layernorm): LayerNorm()\n",
       "  )\n",
       "  (input_embedding): EmbeddingExt(\n",
       "    (rotary_emb): RotaryEmbedding()\n",
       "  )\n",
       "  (position_bias): BucketPositionBias()\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize('Visual Formula 12.14')\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CPMBeeTorch(\n",
       "  (encoder): Encoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-47): 48 x TransformerBlock(\n",
       "        (self_att): SelfAttentionBlock(\n",
       "          (layernorm_before_attention): LayerNorm()\n",
       "          (self_attention): Attention(\n",
       "            (project_q): Linear()\n",
       "            (project_k): Linear()\n",
       "            (project_v): Linear()\n",
       "            (attention_out): Linear()\n",
       "            (softmax): Softmax(dim=-1)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (ffn): FFNBlock(\n",
       "          (layernorm_before_ffn): LayerNorm()\n",
       "          (ffn): FeedForward(\n",
       "            (w_in): DenseGatedACT(\n",
       "              (w_0): Linear()\n",
       "              (w_1): Linear()\n",
       "              (act): GELU(approximate='none')\n",
       "            )\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (w_out): Linear()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (output_layernorm): LayerNorm()\n",
       "  )\n",
       "  (input_embedding): EmbeddingExt(\n",
       "    (rotary_emb): RotaryEmbedding()\n",
       "  )\n",
       "  (position_bias): BucketPositionBias()\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(ckpt_path), strict=True)\n",
    "device = torch.device(\"cuda:0\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "构建dataloader\n",
    "build dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = FinetuneDataset(\n",
    "        dataset_path = \"./decoder_tuning_data//bin_data/{}/train_data\".format(dataset_name),\n",
    "        batch_size=8,\n",
    "        max_length=512,\n",
    "        max_depth=8,\n",
    "        tokenizer=tokenizer,\n",
    "    )\n",
    "val_dataloader = FinetuneDataset(\n",
    "        dataset_path = \"./decoder_tuning_data/bin_data/{}/valid_data\".format(dataset_name),\n",
    "        batch_size=8,\n",
    "        max_length=512,\n",
    "        max_depth=8,\n",
    "        tokenizer=tokenizer,\n",
    "    )\n",
    "test_dataloader = FinetuneDataset(\n",
    "        dataset_path = \"./decoder_tuning_data/bin_data/{}/test_data\".format(dataset_name),\n",
    "        batch_size=8,\n",
    "        max_length=512,\n",
    "        max_depth=8,\n",
    "        tokenizer=tokenizer,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "构建runner\n",
    "\n",
    "Build runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner = DecTCPM(\n",
    "    model = model,\n",
    "    test_dataloader = test_dataloader,\n",
    "    val_dataloader=val_dataloader,\n",
    "    tokenizer = tokenizer,\n",
    "    verbalizer = verbalizer,\n",
    "    device = device,\n",
    "    calibrate_dataloader = None,\n",
    "    lr = lr,\n",
    "    mid_dim = proto_dim,\n",
    "    epochs = max_epochs,\n",
    "    model_logits_weight = model_logits_weight,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "开始训练，最后输出的是zero shot和decoder tuning的准确率\n",
    "\n",
    "Start training, the final output is zero shot and decoder tuning accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runner.run_zs()\n",
    "runner.run(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self = runner\n",
    "for iteration, data in enumerate(test_dataloader):    \n",
    "    logits,hidden_states,label = self.get_logits_and_hidden(data)\n",
    "    proto_logits = self.sim(self.head(hidden_states.float()), self.proto, self.proto_r, logits.float(), self.model_logits_weight).cpu()\n",
    "    pred = torch.argmax(proto_logits, dim=-1).cpu().tolist()\n",
    "    print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input1': '糖尿病该吃什么', 'input2': '糖尿病人的食谱是什么', 'prompt': 'input1和input2是否语义一致？', 'options': {'<option_0>': '不一致', '<option_1>': '同义'}, '<ans>': '<option_1>'}\n",
      "{'input': 'NGC 6231是一个位于天蝎座的疏散星团，天球座标为赤经16时54分，赤纬-41度48分，视觉观测大小约45角分，亮度约2.6视星等，距地球5900光年。NGC 6231年龄约为三百二十万年，是一个非常年轻的星团，星团内的最亮星是5等的天蝎座 ζ1星。用双筒望远镜或小型望远镜就能看到个别的行星。NGC 6231在1654年被意大利天文学家乔瓦尼·巴蒂斯特·霍迪尔纳（Giovanni Battista Hodierna）以Luminosae的名字首次纪录在星表中，但是未见记载于夏尔·梅西耶的天体列表和威廉·赫歇尔的深空天体目录。这个天体在1678年被爱德蒙·哈雷（I.7）、1745年被夏西亚科斯（Jean-Phillippe Loys de Cheseaux）（9）、1751年被尼可拉·路易·拉卡伊（II.13）分别再次独立发现。', 'question': 'NGC 6231被哪些人发现过？', '<ans>': 'NGC 6231在1654年被意大利天文学家乔瓦尼·巴蒂斯特·霍迪尔纳（Giovanni Battista Hodierna）以Luminosae的名字首次纪录在星表中，但是未见记载于夏尔·梅西耶的天体列表和威廉·赫歇尔的深空天体目录。这个天体在1678年被爱德蒙·哈雷（I.7）、1745年被夏西亚科斯（Jean-Phillippe'}\n"
     ]
    }
   ],
   "source": [
    "from cpm_live.generation.bee import CPMBeeBeamSearch\n",
    "data_list = [\n",
    "    {\"input1\": \"糖尿病该吃什么\",\"input2\": \"糖尿病人的食谱是什么\", \"prompt\": \"input1和input2是否语义一致？\",\"options\": {\n",
    "      \"<option_0>\": \"不一致\", \n",
    "      \"<option_1>\": \"同义\"      \n",
    "    },  \"<ans>\": \"\"},\n",
    "    {\"input\": \"NGC 6231是一个位于天蝎座的疏散星团，天球座标为赤经16时54分，赤纬-41度48分，视觉观测大小约45角分，亮度约2.6视星等，距地球5900光年。NGC 6231年龄约为三百二十万年，是一个非常年轻的星团，星团内的最亮星是5等的天蝎座 ζ1星。用双筒望远镜或小型望远镜就能看到个别的行星。NGC 6231在1654年被意大利天文学家乔瓦尼·巴蒂斯特·霍迪尔纳（Giovanni Battista Hodierna）以Luminosae的名字首次纪录在星表中，但是未见记载于夏尔·梅西耶的天体列表和威廉·赫歇尔的深空天体目录。这个天体在1678年被爱德蒙·哈雷（I.7）、1745年被夏西亚科斯（Jean-Phillippe Loys de Cheseaux）（9）、1751年被尼可拉·路易·拉卡伊（II.13）分别再次独立发现。\", \"question\": \"NGC 6231被哪些人发现过？\", \"<ans>\": \"\"}\n",
    "]\n",
    "# use beam search\n",
    "beam_search = CPMBeeBeamSearch(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "for data in data_list:\n",
    "    inference_results = beam_search.generate([data], max_length=100, repetition_penalty=1.1)\n",
    "    for res in inference_results:\n",
    "        print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 召回和匹配"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../src\")\n",
    "sys.path.append(\"/data/nlp/llm/CPM/\")\n",
    "sys.argv=['ipykernel_launcher.py',\n",
    "          '--delta','/data/nlp/llm/CPM/CPM-Bee/src/results/cpm_bee_finetune-delta-best.pt',\n",
    "          '--memory-limit','60',\n",
    "          '--device','cuda'\n",
    "         ]\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0,1'\n",
    "os.environ['FLAGS_eager_delete_tensor_gb'] = \"0.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda-envs/envs/alpaca/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "args = text_generation.parse_args()\n",
    "beam_search = text_generation.load_beam_search(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'document': '老鼠凶狠地指着猫说：我现在和蝙蝠结婚了！将来我们的孩子生活在空中！再也不怕你了！猫哈哈大笑，指了指树上的猫头鹰说：看见没，这是俺<mask_1>！',\n",
       "  '<ans>': '儿子'},\n",
       " {'document': '老鼠凶狠地指着猫说：我现在和蝙蝠结婚了！将来我们的孩子生活在空中！再也不怕你了！猫哈哈大笑，指了指树上的<mask_0>说：看见没，这是俺<mask_1>！',\n",
       "  '<ans>': {'<mask_0>': '鸟窝', '<mask_1>': '儿子'}}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list = [       \n",
    "        {\"document\":\"老鼠凶狠地指着猫说：我现在和蝙蝠结婚了！将来我们的孩子生活在空中！再也不怕你了！猫哈哈大笑，指了指树上的猫头鹰说：看见没，这是俺<mask_1>！\",\n",
    "         \"<ans>\":\"\"},\n",
    "        {\"document\":\"老鼠凶狠地指着猫说：我现在和蝙蝠结婚了！将来我们的孩子生活在空中！再也不怕你了！猫哈哈大笑，指了指树上的<mask_0>说：看见没，这是俺<mask_1>！\",\n",
    "         \"<ans>\":{\"<mask_0>\": \"\",\"<mask_1>\": \"\"}}\n",
    "    ]\n",
    "beam_search.generate(data_list, max_length=256, repetition_penalty=1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'address': '南岸窍角沱正街33号',\n",
       "  'prompt': '将地址里面的省市县区镇村识别出来',\n",
       "  '<ans>': '重庆市南岸区窍角沱正街33号'},\n",
       " {'document': '老鼠凶狠地指着猫说：我现在和蝙蝠结婚了！将来我们的孩子生活在空中！再也不怕你了！猫哈哈大笑，指了指树上的<mask_0>说：看见没，这是俺<mask_1>！',\n",
       "  '<ans>': {'<mask_0>': '鸟窝', '<mask_1>': '儿子'}}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_list = [       \n",
    "        {\"address\":\"南岸窍角沱正街33号\",\"prompt\":\"将地址里面的省市县区镇村识别出来\",\n",
    "         \"<ans>\":\"\"},\n",
    "        {\"document\":\"老鼠凶狠地指着猫说：我现在和蝙蝠结婚了！将来我们的孩子生活在空中！再也不怕你了！猫哈哈大笑，指了指树上的<mask_0>说：看见没，这是俺<mask_1>！\",\n",
    "         \"<ans>\":{\"<mask_0>\": \"\",\"<mask_1>\": \"\"}}\n",
    "    ]\n",
    "beam_search.generate(data_list, max_length=256, repetition_penalty=1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tesla V100S-PCIE-32GB'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "alpaca",
   "language": "python",
   "name": "alpaca"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
